{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fine-Tuning.ipynb",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishrutjai/Deep-Learning/blob/master/Fine_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yufkR8oGJU-d",
        "colab_type": "text"
      },
      "source": [
        "#Fine-tuning the top layers of a a pre-trained network\n",
        "To further improve our previous result, we can try to \"fine-tune\" the last convolutional block of the VGG16 model alongside the top-level classifier. Fine-tuning consist in starting from a trained network, then re-training it on a new dataset using very small weight updates. In our case, this can be done in 3 steps:\n",
        "\n",
        "1. instantiate the convolutional base of VGG16 and load its weights\n",
        "2. add our previously defined fully-connected model on top, and load its weights\n",
        "3. freeze the layers of the VGG16 model up to the last convolutional block\n",
        "\n",
        "![alt text](http://upscfever.com/upsc-fever/images/fine-tuning.png)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-iIjVOPJM47",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#code part 1\n",
        "from bs4 import BeautifulSoup\n",
        "import numpy as np\n",
        "import requests\n",
        "import cv2\n",
        "import PIL.Image\n",
        "import urllib\n",
        "\n",
        "page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n04194289\")#ship synset\n",
        "print(page.content)\n",
        "\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "\n",
        "soup = BeautifulSoup(page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "#print(soup)\n",
        "#print(soup.prettify())\n",
        "\n",
        "#code part 1.1\n",
        "bikes_page = requests.get(\"http://www.image-net.org/api/text/imagenet.synset.geturls?wnid=n02834778\")#bicycle synset\n",
        "print(bikes_page.content)\n",
        "\n",
        "# BeautifulSoup is an HTML parsing library\n",
        "from bs4 import BeautifulSoup\n",
        "bikes_soup = BeautifulSoup(bikes_page.content, 'html.parser')#puts the content of the website into the soup variable, each url on a different line\n",
        "\n",
        "#code part 2\n",
        "str_soup=str(soup)#convert soup to string so it can be split\n",
        "type(str_soup)\n",
        "split_urls=str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(split_urls))#print the length of the list so you know how many urls you have\n",
        "\n",
        "#code part 2.2\n",
        "bikes_str_soup=str(bikes_soup)#convert soup to string so it can be split\n",
        "type(bikes_str_soup)\n",
        "bikes_split_urls=bikes_str_soup.split('\\r\\n')#split so each url is a different possition on a list\n",
        "print(len(bikes_split_urls))\n",
        "\n",
        "#code part 3\n",
        "#check if all the images where stored on the files system\n",
        "!mkdir /content/train #create the Train folder\n",
        "!mkdir /content/train/ships #create the ships folder\n",
        "!mkdir /content/train/bikes #create the bikes folder\n",
        "!mkdir /content/validation\n",
        "!mkdir /content/validation/ships #create the ships folder\n",
        "!mkdir /content/validation/bikes #create the bikes folder\n",
        "#!ls /content/train/ships #list the files inside ships\n",
        "!mkdir /content/test/ \n",
        "!mkdir /content/test/test #list the files inside test\n",
        "\n",
        "#code part 4\n",
        "img_rows, img_cols = 32, 32 #number of rows and columns to convert the images to\n",
        "input_shape = (img_rows, img_cols, 3)#format to store the images (rows, columns,channels) called channels last\n",
        "\n",
        "def url_to_image(url):\n",
        "\t# download the image, convert it to a NumPy array, and then read\n",
        "\t# it into OpenCV format\n",
        "\tresp = urllib.request.urlopen(url)\n",
        "\timage = np.asarray(bytearray(resp.read()), dtype=\"uint8\")\n",
        "\timage = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
        " \n",
        "\t# return the image\n",
        "\treturn image\n",
        "\n",
        "n_of_training_images=150#the number of training images to use\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(n_of_training_images):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[progress])\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/train/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "        \n",
        "#Validation data:\n",
        "\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/ships/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[n_of_training_images+progress])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/validation/bikes/img'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "        \n",
        "print(\"\\nTRAIN:\\n\")          \n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/train/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/train/bikes #list the files inside bikes\n",
        "print(\"\\nVALIDATION:\\n\")\n",
        "print(\"\\nlist the files inside ships directory:\\n\")        \n",
        "!ls /content/validation/ships #list the files inside ships\n",
        "print(\"\\nlist the files inside bikes directory:\\n\")\n",
        "!ls /content/validation/bikes #list the files inside bikes   \n",
        "\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(split_urls[n_of_training_images+progress+50])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/test/test/ships_'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n",
        "#do the same for bikes:\n",
        "for progress in range(50):#store all the images on a directory\n",
        "    # Print out progress whenever progress is a multiple of 20 so we can follow the\n",
        "    # (relatively slow) progress\n",
        "    if(progress%20==0):\n",
        "        print(progress)\n",
        "    if not bikes_split_urls[progress] == None:\n",
        "      try:\n",
        "        I = url_to_image(bikes_split_urls[n_of_training_images+progress+50])#get images that are different from the ones used for training\n",
        "        if (len(I.shape))==3: #check if the image has width, length and channels\n",
        "          save_path = '/content/test/test/bikes_'+str(progress)+'.jpg'#create a name of each image\n",
        "          cv2.imwrite(save_path,I)\n",
        "\n",
        "      except:\n",
        "        None\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sP__IrNZMKf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "# Path to the train folder\n",
        "original_test = '/content/test/test'\n",
        " \n",
        "filenames = os.listdir(original_test)\n",
        "categories = []\n",
        "for filename in filenames:\n",
        "    category = filename.split('_')[0]\n",
        "    if category == 'ships':\n",
        "        categories.append('ships')\n",
        "    else:\n",
        "        categories.append('bikes')\n",
        "\n",
        "data_test = pd.DataFrame({'filename':filenames,'label':categories})\n",
        "\n",
        "data_test.to_csv(\"original_test.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPTrBa_oMqmQ",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning using VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkxopbQPMr9l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QIoIKhfOK1A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzsrjqrGOSfW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.VGG16(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9o1nkiLFICma",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_1mkL4UIHog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.resnet50.ResNet50(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:150]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iu8XFGZeIc5r",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with Xception"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9v5Vg0OCKGCT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.xception.Xception(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45BMWCiwKaV-",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning VGG19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4yRWsmYKPPx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.vgg19.VGG19(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ol7GRcJ2KpyM",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning pretrained ResNet101"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fdUgbZ4fKwLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.resnet.ResNet101(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWaSVWuWK4d8",
        "colab_type": "text"
      },
      "source": [
        "#Load pretrained ResNet152"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTblwTMEK-FZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.resnet.ResNet152(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfYCPPGBLLYn",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning ResNet50v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z7dNlsc7LQ1t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.resnet_v2.ResNet50V2(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxByxfN4Lay8",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with ResNet101v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ZnbwpBkLg7_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.resnet_v2.ResNet101V2(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DfL7H3iLqhS",
        "colab_type": "text"
      },
      "source": [
        "#Fine tune ResNetv152"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HwSm4JfdLvoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.resnet_v2.ResNet152V2(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeVsqtqLL8mb",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with Inceptionv3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oi4OWsI1MCbF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.inception_v3.InceptionV3(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KebaDyLGMRmJ",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with InceptionResNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIX8z9huMXiE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.inception_resnet_v2.InceptionResNetV2(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YfCh452MgJ7",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with MobileNet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZJTx_LfMlhT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.mobilenet.MobileNet(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BNbZvSDMuj8",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with DenseNet121"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8AJxh_OMtrR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.densenet.DenseNet121(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CGiKtXdM6xa",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning with DenseNet169"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MTPa5EZM56D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.densenet.DenseNet169(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVC6C_DwNGnB",
        "colab_type": "text"
      },
      "source": [
        "#Fine tuning DenseNet201"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5jYA89rNM_O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.densenet.DenseNet201(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzSNA8euNSls",
        "colab_type": "text"
      },
      "source": [
        "#Fine tune NasNetLarge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yk-rmWBNRpP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.nasnet.NASNetLarge(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BBtmClwNe44",
        "colab_type": "text"
      },
      "source": [
        "#Fine tune NasNetMobile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbuqwNfDNjze",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.nasnet.NASNetMobile(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVKIPWtjNolu",
        "colab_type": "text"
      },
      "source": [
        "#Fine tune MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QKj6I68PNtx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import applications\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "\n",
        "# dimensions of our images.\n",
        "img_width, img_height = 32, 32\n",
        "\n",
        "train_data_dir = '/content/train'\n",
        "validation_data_dir = '/content/validation'\n",
        "nb_train_samples = 189\n",
        "nb_validation_samples = 59\n",
        "epochs = 5\n",
        "batch_size = 16\n",
        "\n",
        "\n",
        "\n",
        "# prepare data augmentation configuration\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_data_dir,\n",
        "    target_size=(img_height, img_width),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary')\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "# build the VGG16 network\n",
        "\n",
        "input_tensor = Input(shape=(32,32,3))\n",
        "base_model = applications.mobilenet_v2.MobileNetV2(weights='imagenet',include_top= False,input_tensor=input_tensor)\n",
        "top_model = Sequential()\n",
        "top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n",
        "top_model.add(Dense(256, activation='relu'))\n",
        "top_model.add(Dropout(0.5))\n",
        "top_model.add(Dense(1, activation='sigmoid'))\n",
        "model = Model(input= base_model.input, output= top_model(base_model.output))\n",
        "\n",
        "# note that it is necessary to start with a fully-trained\n",
        "# classifier, including the top classifier,\n",
        "# in order to successfully do fine-tuning\n",
        "\n",
        "# add the model on top of the convolutional base\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# set the first 25 layers (up to the last conv block)\n",
        "# to non-trainable (weights will not be updated)\n",
        "for layer in model.layers[:25]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# compile the model with a SGD/momentum optimizer\n",
        "# and a very slow learning rate.\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# fine-tune the model\n",
        "model.fit_generator(\n",
        "    train_generator,\n",
        "    samples_per_epoch=nb_train_samples,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_generator,\n",
        "    nb_val_samples=nb_validation_samples)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP66eSTRNzXv",
        "colab_type": "text"
      },
      "source": [
        "#Thanks for completing this notebook"
      ]
    }
  ]
}