{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras-Datasets.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishrutjai/Deep-Learning/blob/master/Keras_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4btuW8nO0zDC",
        "colab_type": "text"
      },
      "source": [
        "#Datasets\n",
        "\n",
        "##CIFAR10 small image classification\n",
        "\n",
        "Dataset of 50,000 32x32 color training images, labeled over 10 categories, and 10,000 test images.\n",
        "\n",
        "##Usage:\n",
        "```\n",
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "```\n",
        "\n",
        "##Returns:\n",
        "2 tuples:\n",
        "\n",
        "1. x_train, x_test: uint8 array of RGB image data with shape (num_samples, 3, 32, 32) or (num_samples, 32, 32, 3) based on the image_data_format backend setting of either channels_first or channels_last respectively.\n",
        "2. y_train, y_test: uint8 array of category labels (integers in range 0-9) with shape (num_samples, 1)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LaNdjIV20RV7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41TEK1VX1rxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "\n",
        "from keras import models\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from keras.datasets import mnist\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "from IPython.display import SVG\n",
        "\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
        "\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3)\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test =  to_categorical(y_test, 10)\n",
        "\n",
        "initializer = keras.initializers.glorot_normal(seed=None)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(10, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(x_train, y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=10,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnAIQNqP1IW8",
        "colab_type": "text"
      },
      "source": [
        "#CIFAR100 small image classification\n",
        "\n",
        "Dataset of 50,000 32x32 color training images, labeled over 100 categories, and 10,000 test images.\n",
        "\n",
        "##Usage:\n",
        "```\n",
        "from keras.datasets import cifar100\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "```\n",
        "\n",
        "##Returns:\n",
        "\n",
        "2 tuples:\n",
        "1. x_train, x_test: uint8 array of RGB image data with shape (num_samples, 3, 32, 32) or (num_samples, 32, 32, 3) based on the image_data_format backend setting of either channels_first or channels_last respectively.\n",
        "2. y_train, y_test: uint8 array of category labels with shape (num_samples, 1).\n",
        "Arguments:\n",
        "\n",
        "label_mode: \"fine\" or \"coarse\".\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciSErDGQ2sPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import cifar100\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (x_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (x_test.shape, y_test.shape))\n",
        "\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(x_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()\n",
        "\n",
        "x_train = x_train.reshape(50000, 32 * 32 * 3)\n",
        "x_test = x_test.reshape(10000, 32 * 32 * 3)\n",
        "\n",
        "#preprocess\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255.0\n",
        "x_test /= 255.0\n",
        "\n",
        "#change labels from numeric to one hot encoded\n",
        "y_train = to_categorical(y_train, 100)\n",
        "y_test =  to_categorical(y_test, 100)\n",
        "\n",
        "initializer = keras.initializers.glorot_normal(seed=None)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(1024, input_shape=(3072,), kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(512, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(100, kernel_initializer=initializer, bias_initializer=initializer))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "    \n",
        " \n",
        "\n",
        "# training\n",
        "history = model.fit(x_train, y_train,\n",
        "                        batch_size=128,\n",
        "                        nb_epoch=10,\n",
        "                        verbose=1,\n",
        "                        validation_data=(x_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cR2uWgSN271m",
        "colab_type": "text"
      },
      "source": [
        "#MNIST database of handwritten digits\n",
        "\n",
        "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
        "\n",
        "##Usage:\n",
        "```\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "```\n",
        "\n",
        "##Returns:\n",
        "\n",
        "2 tuples:\n",
        "1. x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
        "2. y_train, y_test: uint8 array of digit labels (integers in range 0-9) with shape (num_samples,).\n",
        "\n",
        "##Arguments:\n",
        "\n",
        "1. path: if you do not have the index file locally (at '~/.keras/datasets/' + path), it will be downloaded to this location."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhDZZnZl3MvH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))\n",
        "\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "# Categorically encode labels\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))\n",
        "\n",
        "score = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UiJLKoeC3T0b",
        "colab_type": "text"
      },
      "source": [
        "#Fashion-MNIST database of fashion articles\n",
        "\n",
        "Dataset of 60,000 28x28 grayscale images of 10 fashion categories, along with a test set of 10,000 images. This dataset can be used as a drop-in replacement for MNIST. The class labels are:\n",
        "\n",
        "Label\tDescription\n",
        "0\tT-shirt/top\n",
        "1\tTrouser\n",
        "2\tPullover\n",
        "3\tDress\n",
        "4\tCoat\n",
        "5\tSandal\n",
        "6\tShirt\n",
        "7\tSneaker\n",
        "8\tBag\n",
        "9\tAnkle boot\n",
        "\n",
        "##Usage:\n",
        "```\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "```\n",
        "\n",
        "##Returns:\n",
        "2 tuples:\n",
        "\n",
        "1. x_train, x_test: uint8 array of grayscale image data with shape (num_samples, 28, 28).\n",
        "2. y_train, y_test: uint8 array of labels (integers in range 0-9) with shape (num_samples,)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmr8UMWN3dfS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# summarize loaded dataset\n",
        "print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))\n",
        "print('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))\n",
        "\n",
        "# plot first few images\n",
        "for i in range(9):\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(330 + 1 + i)\n",
        "\t# plot raw pixel data\n",
        "\tpyplot.imshow(X_train[i], cmap=pyplot.get_cmap('gray'))\n",
        "# show the figure\n",
        "pyplot.show()\n",
        "\n",
        "NUM_ROWS = 28\n",
        "NUM_COLS = 28\n",
        "NUM_CLASSES = 10\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10\n",
        "\n",
        "\n",
        "# Reshape data\n",
        "X_train = X_train.reshape((X_train.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_train = X_train.astype('float32') / 255\n",
        "X_test = X_test.reshape((X_test.shape[0], NUM_ROWS * NUM_COLS))\n",
        "X_test = X_test.astype('float32') / 255\n",
        "\n",
        "y_train = to_categorical(y_train, NUM_CLASSES)\n",
        "y_test = to_categorical(y_test, NUM_CLASSES)\n",
        "\n",
        "# Build neural network\n",
        "model = models.Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(NUM_ROWS * NUM_COLS,)))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='rmsprop',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=1,\n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUDauZ1m3yVy",
        "colab_type": "text"
      },
      "source": [
        "#Thank you for completing this notebook"
      ]
    }
  ]
}